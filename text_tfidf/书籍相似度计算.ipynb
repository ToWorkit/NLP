{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Just Do It\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:860: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "# 判断鬼吹灯和盗墓笔记以及老九门的相似度\n",
    "# https://www.cnblogs.com/iloveai/p/gensim_tutorial.html\n",
    "'''\n",
    "Gensim是一款开源的第三方Python工具包，用于从原始的非结构化的文本中，无监督地学习到文本隐层的主题向量表达。\n",
    "它支持包括TF-IDF，LSA，LDA，和word2vec在内的多种主题模型算法，\n",
    "支持流式训练，并提供了诸如相似度计算，信息检索等一些常用任务的API接口\n",
    "'''\n",
    "# api说明\n",
    "# 建立语料特征，模型(TFIDF)，相似度\n",
    "from gensim import corpora, models, similarities\n",
    "import jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\JUSTDO~1\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.868 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "# 分词处理\n",
    "# 导入文件\n",
    "with open('./老九门.txt', 'r', encoding = 'utf-8') as f_:\n",
    "    data_ljm = f_.read()\n",
    "# 引入鬼吹灯\n",
    "with open('./鬼吹灯.txt', 'r', encoding = 'utf-8') as f_2:\n",
    "    data_gcd = f_2.read()\n",
    "# 引入血尸\n",
    "with open('./血尸.txt', 'r', encoding = 'utf-8') as f_4:\n",
    "    data_xs = f_4.read()\n",
    "    \n",
    "# 分词\n",
    "data_gcd_op = jieba.cut(data_gcd)\n",
    "# 处理格式\n",
    "data_gcd_str = ''\n",
    "for item in data_gcd_op:\n",
    "    data_gcd_str += item + ' '\n",
    "\n",
    "# 分词\n",
    "data_xs_op = jieba.cut(data_xs)\n",
    "# 处理格式\n",
    "data_xs_str = ''\n",
    "for item in data_xs_op:\n",
    "    data_xs_str += item + ' '    \n",
    "    \n",
    "# 分词并处理格式\n",
    "data_ljm_op = jieba.cut(data_ljm)\n",
    "# for item in data_ljm:\n",
    "#     print(item)\n",
    "# 拼接起来\n",
    "# \"词语1 词语2 词语3 … 词语n\"\n",
    "data_ljm_str = ''\n",
    "for item in data_ljm_op:\n",
    "    data_ljm_str += item + ' '\n",
    "# print(data_ljm_str)\n",
    "\n",
    "# 放入列表中\n",
    "documents = [data_ljm_str, data_gcd_str, data_xs_str]\n",
    "# print(type(documents))\n",
    "# 放到二维数组中去\n",
    "texts = [[word for word in document.split()] for document in documents]\n",
    "# documents = ['你,好啊', '很好,的']\n",
    "# texts = [[i for i in item.split()]for item in documents]\n",
    "# print(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.liaoxuefeng.com/wiki/001374738125095c955c1e6d8bb493182103fac9270762a000/001411031239400f7181f65f33a4623bc42276a605debf6000\n",
    "# 使用dict时，如果引用的Key不存在，就会抛出KeyError。如果希望key不存在时，返回一个默认值，就可以用defaultdict：\n",
    "from collections import defaultdict\n",
    "# 词频 \n",
    "frequency = defaultdict(int)\n",
    "for text in texts:\n",
    "    for token in text:\n",
    "        # 计算词出现的频率 {'token(词语)': 'value'}\n",
    "        frequency[token] += 1\n",
    "# 将词频低的词语过滤掉\n",
    "texts = [[token for token in text if frequency[token] > 25] for text in texts]\n",
    "# print(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 建立语料特征词典\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "# dictionary.save('./12345.txt') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('./盗墓笔记.TXT', 'r', encoding = 'utf-8') as f_1:\n",
    "    data_dmbj = f_1.read()\n",
    "data_dmbj_op = jieba.cut(data_dmbj)\n",
    "data_dmbj_str = ''\n",
    "for item in data_dmbj_op:\n",
    "    data_dmbj_str += item + ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 将要对比的文档通过doc2bow转为稀疏向量\n",
    "data_dmbj_str_vec = dictionary.doc2bow(data_dmbj_str.split())\n",
    "\n",
    "texts_vec = [dictionary.doc2bow(text) for text in texts]\n",
    "# 保存稀疏向量语料库\n",
    "# corpora.MmCorpus.serialize('./6562.txt',texts_vec) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.23141621  0.55574089  0.03429166]\n"
     ]
    }
   ],
   "source": [
    "# 通过tfidfmodel进行处理得到tfidf\n",
    "tfidf = models.TfidfModel(texts_vec)\n",
    "# 通过token2id得到特征数\n",
    "fetureNum = len(dictionary.token2id.keys())\n",
    "# 稀疏矩阵相似度\n",
    "# params -> 稀疏向量后的tfidf，特征数\n",
    "index = similarities.SparseMatrixSimilarity(tfidf[texts_vec], num_features = fetureNum)\n",
    "# 建立索引，计算相似度\n",
    "sims = index[tfidf[data_dmbj_str_vec]]\n",
    "# 血尸的相似度会被稀疏掉\n",
    "print(sims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
